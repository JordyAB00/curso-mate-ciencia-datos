<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ética y Gobernanza de Datos en IA - Semana 1</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            overflow: hidden;
            background: #f5f5f7;
        }

        .presentation-container {
            width: 100vw;
            height: 100vh;
            position: relative;
        }

        .slide {
            width: 100%;
            height: 100%;
            position: absolute;
            top: 0;
            left: 0;
            opacity: 0;
            transition: opacity 0.6s ease-in-out;
            display: flex;
            flex-direction: column;
            padding: 50px 80px 140px 80px;
            background: #f5f5f7;
        }

        .slide.active {
            opacity: 1;
            z-index: 1;
        }

        .slide-header {
            margin-bottom: 40px;
        }

        .slide-title {
            font-size: 42px;
            font-weight: 700;
            color: #2d1b4e;
            margin-bottom: 12px;
        }

        .slide-subtitle {
            font-size: 20px;
            color: #6e6e73;
            font-weight: 300;
        }

        .slide-content {
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: flex-start;
            gap: 20px;
            overflow-y: auto;
            max-height: calc(100vh - 280px);
        }

        .content-box {
            background: #ffffff;
            border-radius: 20px;
            padding: 20px;
            border: 1px solid #e5e5e7;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
        }

        .content-box h3 {
            font-size: 24px;
            color: #2d1b4e;
            margin-bottom: 12px;
        }

        .content-box p {
            font-size: 16px;
            color: #1d1d1f;
            line-height: 1.5;
        }

        .content-box ul {
            list-style: none;
            padding-left: 0;
        }

        .content-box li {
            font-size: 16px;
            color: #1d1d1f;
            line-height: 1.6;
            padding-left: 25px;
            position: relative;
            margin-bottom: 8px;
        }

        .content-box li::before {
            content: "▸";
            position: absolute;
            left: 0;
            color: #00d4ff;
            font-size: 20px;
        }

        .two-columns {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }

        .three-columns {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 18px;
        }

        .case-card {
            background: #ffffff;
            border-radius: 15px;
            padding: 18px;
            border: 1px solid #e5e5e7;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .case-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 20px rgba(45, 27, 78, 0.15);
            border-color: #00d4ff;
        }

        .case-card h4 {
            font-size: 19px;
            color: #2d1b4e;
            margin-bottom: 8px;
        }

        .case-card p {
            font-size: 14px;
            color: #1d1d1f;
            line-height: 1.4;
        }

        .highlight-box {
            background: linear-gradient(135deg, #f0f0f2, #ffffff);
            border-left: 4px solid #00d4ff;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
        }

        .highlight-box p {
            font-size: 17px;
            color: #2d1b4e;
            font-style: italic;
            font-weight: 500;
        }

        .comparison-table {
            background: #ffffff;
            border-radius: 15px;
            overflow: hidden;
            border: 1px solid #e5e5e7;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
        }

        .comparison-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .comparison-table th {
            background: linear-gradient(90deg, #2d1b4e, #00d4ff);
            color: #ffffff;
            padding: 12px;
            font-size: 16px;
            text-align: left;
        }

        .comparison-table td {
            padding: 12px;
            font-size: 14px;
            color: #1d1d1f;
            border-bottom: 1px solid #f5f5f7;
        }

        .navigation {
            position: fixed;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 20px;
            z-index: 1000;
        }

        .nav-button {
            background: linear-gradient(135deg, #7c3aed, #00d4ff);
            border: none;
            color: white;
            padding: 15px 30px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 212, 255, 0.3);
        }

        .nav-button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 212, 255, 0.4);
        }

        .nav-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .logo-area {
            position: fixed;
            top: 15px;
            left: 20px;
            z-index: 1000;
        }

        .logo-image {
            max-width: 150px;
            height: auto;
        }

        .slide-number {
            position: fixed;
            top: 20px;
            right: 30px;
            color: #6e6e73;
            font-size: 16px;
            z-index: 1000;
            font-weight: 500;
        }

        .cover-slide {
            justify-content: center;
            align-items: center;
            text-align: center;
            background: linear-gradient(135deg, #ffffff 0%, #f5f5f7 50%, #ffffff 100%);
            padding: 60px 80px 140px 80px;
        }

        .cover-title {
            font-size: 64px;
            font-weight: 800;
            background: linear-gradient(90deg, #2d1b4e, #00d4ff, #2d1b4e);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 20px;
            animation: gradient 3s ease infinite;
            background-size: 200% 200%;
        }

        @keyframes gradient {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }

        .cover-subtitle {
            font-size: 32px;
            color: #6e6e73;
            margin-bottom: 30px;
            font-weight: 300;
        }

        .cover-info {
            font-size: 18px;
            color: #1d1d1f;
            margin-top: 30px;
            line-height: 1.6;
        }

        .stat-box {
            background: #ffffff;
            border-radius: 15px;
            padding: 15px;
            text-align: center;
            border: 2px solid #e5e5e7;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            transition: all 0.3s ease;
        }

        .stat-box:hover {
            border-color: #00d4ff;
            box-shadow: 0 4px 12px rgba(0, 212, 255, 0.15);
        }

        .stat-number {
            font-size: 36px;
            font-weight: 700;
            background: linear-gradient(90deg, #2d1b4e, #00d4ff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 8px;
        }

        .stat-label {
            font-size: 14px;
            color: #6e6e73;
        }

        .key-point {
            background: #ffffff;
            border-left: 4px solid #00d4ff;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
            border: 1px solid #e5e5e7;
            border-left: 4px solid #00d4ff;
        }

        .key-point h4 {
            color: #2d1b4e;
            font-size: 18px;
            margin-bottom: 8px;
        }

        .key-point p {
            color: #1d1d1f;
            font-size: 15px;
            line-height: 1.5;
        }
    </style>
</head>
<body>
    <div class="logo-area">
        <img src="../../assets/images/logo-ulacit.png" alt="ULACIT" class="logo-image">
    </div>

    <div class="slide-number">
        <span id="currentSlide">1</span> / <span id="totalSlides">15</span>
    </div>

    <div class="presentation-container">
        <!-- Slide 1: Portada -->
        <div class="slide cover-slide active">
            <h1 class="cover-title">Ética y Gobernanza de Datos en IA</h1>
            <p class="cover-subtitle">Semana 1: Fundamentos y casos críticos</p>
            <div class="cover-info">
                <p>Microcredencial en Inteligencia Artificial y Análisis de Datos<br>
                Universidad Latinoamericana de Ciencia y Tecnología<br>
                Diciembre 2025</p>
            </div>
        </div>

        <!-- Slide 2: Introducción -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Introducción a la ética y gobernanza en IA</h2>
                <p class="slide-subtitle">¿Por qué es importante?</p>
            </div>
            <div class="slide-content">
                <div class="content-box">
                    <h3>Conceptos fundamentales</h3>
                    <ul>
                        <li><strong>Ética:</strong> Principios que guían la conducta correcta y el desarrollo responsable de sistemas de IA</li>
                        <li><strong>Moral:</strong> Conjunto de valores y normas de una sociedad que determinan lo aceptable</li>
                        <li><strong>Gobernanza:</strong> Estructuras, políticas y mecanismos para asegurar uso ético y responsable de datos e IA</li>
                    </ul>
                </div>
                <div class="highlight-box">
                    <p>La ética en IA no es un obstáculo para la innovación, es la condición necesaria para una tecnología que beneficie a toda la humanidad.</p>
                </div>
            </div>
        </div>

        <!-- Slide 3: Diferencia ética vs gobernanza -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Ética en IA vs. Gobernanza de datos en IA</h2>
                <p class="slide-subtitle">Dos caras de la misma moneda</p>
            </div>
            <div class="slide-content">
                <div class="comparison-table">
                    <table>
                        <thead>
                            <tr>
                                <th>Aspecto</th>
                                <th>Ética en IA</th>
                                <th>Gobernanza de datos en IA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Enfoque</td>
                                <td>Principios y valores morales</td>
                                <td>Estructuras organizacionales y procesos</td>
                            </tr>
                            <tr>
                                <td>Pregunta clave</td>
                                <td>¿Qué debemos hacer?</td>
                                <td>¿Cómo lo hacemos?</td>
                            </tr>
                            <tr>
                                <td>Resultado</td>
                                <td>Lineamientos éticos y principios</td>
                                <td>Políticas, roles, procedimientos</td>
                            </tr>
                            <tr>
                                <td>Ejemplo</td>
                                <td>Equidad, transparencia, privacidad</td>
                                <td>Comités de ética, data stewards, auditorías</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="highlight-box">
                    <p>La ética define el "qué" (principios), mientras que la gobernanza define el "cómo" (implementación).</p>
                </div>
            </div>
        </div>

        <!-- Slide 4: Casos de fallas éticas -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Casos famosos de fallas éticas en IA</h2>
                <p class="slide-subtitle">Lecciones aprendidas</p>
            </div>
            <div class="slide-content">
                <div class="three-columns">
                    <div class="case-card">
                        <h4>Amazon Hiring Algorithm (2018)</h4>
                        <p>Sistema de contratación con sesgo de género. Penalizaba CVs con la palabra "women" y favorecía candidatos masculinos.</p>
                    </div>
                    <div class="case-card">
                        <h4>COMPAS (2016-presente)</h4>
                        <p>Algoritmo de predicción de reincidencia criminal con sesgo racial. Falsos positivos más altos en afroamericanos.</p>
                    </div>
                    <div class="case-card">
                        <h4>Google Gemini (2024)</h4>
                        <p>Generación de imágenes históricas inexactas. Diversificación excesiva comprometió precisión histórica.</p>
                    </div>
                </div>
                <div class="two-columns" style="margin-top: 25px;">
                    <div class="case-card">
                        <h4>ChatGPT y suicidio (2023)</h4>
                        <p>Caso de joven belga Eliza: ChatGPT proporcionó respuestas que contribuyeron a decisión suicida. Falta de salvaguardas en salud mental.</p>
                    </div>
                    <div class="case-card">
                        <h4>Taylor Swift deepfakes (2024)</h4>
                        <p>Imágenes sexuales generadas con IA circularon en redes. 47M de visualizaciones antes de ser removidas. Violación de privacidad y dignidad.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 5: Impacto de las fallas -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Impacto real de las fallas éticas</h2>
                <p class="slide-subtitle">Más allá del daño reputacional</p>
            </div>
            <div class="slide-content">
                <div class="two-columns">
                    <div class="content-box">
                        <h3>Consecuencias individuales</h3>
                        <ul>
                            <li>Discriminación en empleo, crédito, vivienda</li>
                            <li>Encarcelamiento injusto o condenas más severas</li>
                            <li>Violación de privacidad y dignidad</li>
                            <li>Daño psicológico y salud mental</li>
                            <li>Pérdida de confianza en instituciones</li>
                        </ul>
                    </div>
                    <div class="content-box">
                        <h3>Consecuencias organizacionales</h3>
                        <ul>
                            <li>Daño reputacional masivo</li>
                            <li>Pérdida de confianza del público</li>
                            <li>Sanciones regulatorias (hasta €35M o 7% facturación)</li>
                            <li>Demandas y litigios costosos</li>
                            <li>Abandono de proyectos (como Amazon Hiring)</li>
                        </ul>
                    </div>
                </div>
                <div class="highlight-box" style="margin-top: 25px;">
                    <p>Las fallas éticas en IA no son hipotéticas: tienen consecuencias reales, medibles y a menudo devastadoras para individuos y organizaciones.</p>
                </div>
            </div>
        </div>

        <!-- Slide 6: Principales preocupaciones -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Panorama global: preocupaciones éticas principales</h2>
                <p class="slide-subtitle">Tendencias 2024-2025</p>
            </div>
            <div class="slide-content">
                <div class="three-columns">
                    <div class="stat-box">
                        <div class="stat-number">#1</div>
                        <div class="stat-label">Desinformación<br>(WEF 2024)</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-number">70%</div>
                        <div class="stat-label">Adolescentes EE.UU. usan IA generativa</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-number">49%</div>
                        <div class="stat-label">Empresas sufrieron deepfakes 2024</div>
                    </div>
                </div>
                <div class="two-columns" style="margin-top: 25px;">
                    <div class="content-box">
                        <h3>Top 5 preocupaciones globales</h3>
                        <ul>
                            <li>Desinformación y deepfakes</li>
                            <li>Sesgo algorítmico y discriminación</li>
                            <li>Privacidad y vigilancia masiva</li>
                            <li>Impacto laboral y desempleo</li>
                            <li>Propiedad intelectual en IA generativa</li>
                        </ul>
                    </div>
                    <div class="highlight-box">
                        <p>El sesgo algorítmico fue incluido explícitamente como nueva preocupación formal por la OCDE en 2024, reflejando su criticidad en salud, empleo y justicia.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 7: Framework FATE -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Framework FATE</h2>
                <p class="slide-subtitle">Principios fundamentales de ética en IA</p>
            </div>
            <div class="slide-content">
                <div class="two-columns">
                    <div class="content-box">
                        <h3>Fairness (Equidad)</h3>
                        <p>Los sistemas de IA deben tratar a todos de manera justa, sin discriminación por raza, género, edad u otras características protegidas.</p>
                    </div>
                    <div class="content-box">
                        <h3>Accountability (Responsabilidad)</h3>
                        <p>Debe existir una cadena clara de responsabilidad desde el desarrollo hasta la implementación y uso de sistemas de IA.</p>
                    </div>
                </div>
                <div class="two-columns" style="margin-top: 20px;">
                    <div class="content-box">
                        <h3>Transparency (Transparencia)</h3>
                        <p>Las personas tienen derecho a saber cuándo interactúan con IA y cómo funcionan los sistemas que les afectan.</p>
                    </div>
                    <div class="content-box">
                        <h3>Explicability (Explicabilidad)</h3>
                        <p>Los sistemas deben poder explicar sus decisiones de manera comprensible, especialmente en contextos críticos como salud o justicia.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 8: Beneficencia y privacidad -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Principios complementarios</h2>
                <p class="slide-subtitle">Más allá de FATE</p>
            </div>
            <div class="slide-content">
                <div class="content-box">
                    <h3>Beneficencia y no maleficencia</h3>
                    <ul>
                        <li><strong>Beneficencia:</strong> Los sistemas de IA deben diseñarse para beneficiar a las personas y la sociedad</li>
                        <li><strong>No maleficencia:</strong> "Primero, no hacer daño" - evitar consecuencias negativas previsibles</li>
                        <li><strong>Ejemplo:</strong> Sistemas de diagnóstico médico deben maximizar beneficios (detección temprana) mientras minimizan riesgos (falsos positivos/negativos)</li>
                    </ul>
                </div>
                <div class="content-box" style="margin-top: 20px;">
                    <h3>Privacidad y protección de datos</h3>
                    <ul>
                        <li>Derecho fundamental reconocido por GDPR, Ley 8968 (Costa Rica) y regulaciones globales</li>
                        <li>Incluye: consentimiento informado, minimización de datos, propósito específico</li>
                        <li>Técnicas clave: anonimización, seudonimización, privacy by design</li>
                        <li>Derechos ARCO: Acceso, Rectificación, Cancelación, Oposición</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Slide 9: Dilemas éticos -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Dilemas éticos en IA</h2>
                <p class="slide-subtitle">Trade-offs difíciles</p>
            </div>
            <div class="slide-content">
                <div class="two-columns">
                    <div class="key-point">
                        <h4>Precisión vs. Equidad</h4>
                        <p>Un modelo más preciso puede ser menos equitativo entre grupos. ¿Optimizamos precisión global o equidad entre subgrupos?</p>
                    </div>
                    <div class="key-point">
                        <h4>Privacidad vs. Utilidad</h4>
                        <p>Más datos mejoran modelos pero comprometen privacidad. ¿Dónde trazamos la línea?</p>
                    </div>
                </div>
                <div class="two-columns" style="margin-top: 20px;">
                    <div class="key-point">
                        <h4>Transparencia vs. Propiedad intelectual</h4>
                        <p>Revelar el funcionamiento puede comprometer ventajas competitivas. ¿Cuánta transparencia es suficiente?</p>
                    </div>
                    <div class="key-point">
                        <h4>Automatización vs. Empleo</h4>
                        <p>La eficiencia puede desplazar empleos. ¿Cómo balanceamos innovación con impacto social?</p>
                    </div>
                </div>
                <div class="highlight-box" style="margin-top: 25px;">
                    <p>No existen soluciones perfectas. La ética en IA requiere navegar trade-offs complejos con transparencia y responsabilidad.</p>
                </div>
            </div>
        </div>

        <!-- Slide 10: Explicabilidad (XAI) -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Explainable AI (XAI)</h2>
                <p class="slide-subtitle">Del "black box" a la transparencia</p>
            </div>
            <div class="slide-content">
                <div class="content-box">
                    <h3>¿Por qué necesitamos explicabilidad?</h3>
                    <p>En contextos críticos (salud, justicia, crédito), las personas tienen derecho a entender por qué un sistema tomó una decisión que les afecta.</p>
                </div>
                <div class="two-columns" style="margin-top: 20px;">
                    <div class="content-box">
                        <h3>Métodos principales</h3>
                        <ul>
                            <li><strong>LIME:</strong> Local Interpretable Model-agnostic Explanations</li>
                            <li><strong>SHAP:</strong> SHapley Additive exPlanations</li>
                            <li><strong>Attention mechanisms:</strong> Visualización de qué inputs influencian outputs</li>
                        </ul>
                    </div>
                    <div class="key-point">
                        <h4>Trade-off crítico</h4>
                        <p>Modelos más complejos (deep learning) tienden a ser más precisos pero menos explicables. Modelos simples (regresión) son más explicables pero potencialmente menos precisos.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 11: Panorama regulatorio -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Panorama regulatorio global</h2>
                <p class="slide-subtitle">Estado actual diciembre 2025</p>
            </div>
            <div class="slide-content">
                <div class="key-point">
                    <h4>EU AI Act (vigente desde agosto 2024)</h4>
                    <p>Sistema de clasificación por riesgo: inaceptable, alto, limitado, mínimo. Sanciones: hasta €35M o 7% de facturación global. Aplicación completa: agosto 2026.</p>
                </div>
                <div class="key-point">
                    <h4>Estados Unidos (2025)</h4>
                    <p>Giro significativo: revocación de Orden Ejecutiva de Biden. Enfoque de mínima regulación federal. Única ley federal: TAKE IT DOWN Act (criminaliza deepfakes no consensuales).</p>
                </div>
                <div class="key-point">
                    <h4>China</h4>
                    <p>AI Safety Governance Framework 2.0 (sept 2025). Etiquetado obligatorio de contenido AI. Plan de Acción Global de Gobernanza de IA (julio 2025).</p>
                </div>
                <div class="key-point">
                    <h4>América Latina</h4>
                    <p>Brasil: Ley de IA (dic 2024). Perú: primera ley de IA regional. Chile lidera en preparación. IA representará 5.4% del PIB regional para 2030.</p>
                </div>
            </div>
        </div>

        <!-- Slide 12: Costa Rica pionero -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Costa Rica: pionero centroamericano</h2>
                <p class="slide-subtitle">Estrategia Nacional de IA 2024-2027</p>
            </div>
            <div class="slide-content">
                <div class="content-box">
                    <h3>Hitos históricos</h3>
                    <ul>
                        <li>Primer país de Centroamérica y el Caribe con Estrategia Nacional de IA (octubre 2024)</li>
                        <li>Co-facilita (con España) el Diálogo Global sobre Gobernanza de IA en ONU</li>
                        <li>Estrategia alineada con Recomendación UNESCO y Principios OCDE</li>
                    </ul>
                </div>
                <div class="two-columns" style="margin-top: 30px;">
                    <div class="content-box">
                        <h3>7 Principios rectores</h3>
                        <ul>
                            <li>Paz y dignidad humana</li>
                            <li>Supervisión humana</li>
                            <li>Transparencia y explicabilidad</li>
                            <li>Equidad y no discriminación</li>
                            <li>Responsabilidad</li>
                            <li>Sostenibilidad y bienestar</li>
                            <li>Seguridad de la información</li>
                        </ul>
                    </div>
                    <div class="highlight-box">
                        <p>"Estamos muy felices de que Costa Rica sea pionero en la región de Centroamérica en la elaboración de una política de inteligencia artificial ética, justa, al servicio de la sociedad."</p>
                        <p style="font-size: 16px; margin-top: 10px;">— Gabriela Ramos, Directora General Adjunta UNESCO</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 13: Preocupaciones actuales -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Principales preocupaciones éticas actuales</h2>
                <p class="slide-subtitle">Diciembre 2025</p>
            </div>
            <div class="slide-content">
                <div class="three-columns">
                    <div class="stat-box">
                        <div class="stat-number">#1</div>
                        <div class="stat-label">Desinformación y deepfakes (WEF 2024)</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-number">487</div>
                        <div class="stat-label">Ataques deepfakes en Q2 2025 (+41% vs Q1)</div>
                    </div>
                    <div class="stat-box">
                        <div class="stat-number">400%</div>
                        <div class="stat-label">Aumento deepfakes CSAM (H1 2025 vs 2024)</div>
                    </div>
                </div>
                <div class="two-columns" style="margin-top: 30px;">
                    <div class="case-card">
                        <h4>Sesgo algorítmico</h4>
                        <p>Crítico en salud, empleo y justicia. OCDE 2024 incluyó explícitamente como nueva preocupación formal. Requiere "algovigilancia" continua.</p>
                    </div>
                    <div class="case-card">
                        <h4>Privacidad y vigilancia</h4>
                        <p>49% de empresas experimentaron deepfakes audio/video en 2024. Balance innovación vs. protección sin resolver.</p>
                    </div>
                    <div class="case-card">
                        <h4>Impacto laboral</h4>
                        <p>OIT y FMI señalan transformación disruptiva. Principios OCDE enfatizan derechos laborales en automatización.</p>
                    </div>
                    <div class="case-card">
                        <h4>IA generativa</h4>
                        <p>70% adolescentes EE.UU. y 80% UK la usan. Preocupaciones sobre propiedad intelectual y datos de entrenamiento.</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 14: Actividad -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Actividad práctica</h2>
                <p class="slide-subtitle">Análisis de casos reales</p>
            </div>
            <div class="slide-content">
                <div class="content-box">
                    <h3>Instrucciones</h3>
                    <p>En equipos, seleccionen uno de los casos presentados y analicen:</p>
                    <ul>
                        <li>¿Cuáles fueron los dilemas éticos presentes?</li>
                        <li>¿Qué principios del framework FATE fueron violados?</li>
                        <li>¿Cuáles fueron las causas raíz del problema?</li>
                        <li>¿Qué stakeholders fueron afectados y cómo?</li>
                        <li>¿Qué controles de gobernanza de datos faltaron?</li>
                        <li>¿Qué recomendaciones habrían prevenido el incidente?</li>
                    </ul>
                </div>
                <div class="two-columns" style="margin-top: 30px;">
                    <div class="case-card">
                        <h4>Casos disponibles</h4>
                        <p>• Amazon Hiring Algorithm<br>
                        • COMPAS<br>
                        • Google Gemini<br>
                        • ChatGPT y suicidio<br>
                        • Taylor Swift deepfakes</p>
                    </div>
                    <div class="case-card">
                        <h4>Formato de entrega</h4>
                        <p>• Documento: 3-5 páginas<br>
                        • Presentación oral: 7-10 min<br>
                        • Aplicar marcos teóricos estudiados<br>
                        • Mínimo 3 referencias APA 7</p>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 15: Conclusión -->
        <div class="slide">
            <div class="slide-header">
                <h2 class="slide-title">Conclusiones clave</h2>
                <p class="slide-subtitle">Hacia una IA ética y bien gobernada</p>
            </div>
            <div class="slide-content">
                <div class="key-point">
                    <h4>La ética y la gobernanza no son obstáculos, son condiciones necesarias</h4>
                    <p>Para una IA que beneficie a la humanidad, debemos integrar reflexión ética, marcos de gobernanza robustos y mecanismos de rendición de cuentas desde el diseño inicial.</p>
                </div>
                <div class="key-point">
                    <h4>Las fallas éticas tienen consecuencias reales</h4>
                    <p>No son hipotéticas: afectan empleos, dignidad, salud mental y procesos democráticos. Los casos documentados muestran patrones recurrentes que podemos prevenir.</p>
                </div>
                <div class="key-point">
                    <h4>Costa Rica lidera en la región</h4>
                    <p>Como pionero centroamericano, tenemos la oportunidad única de estudiar cómo principios internacionales se adaptan a realidades locales.</p>
                </div>
                <div class="highlight-box">
                    <p style="text-align: center; font-size: 24px;">El futuro de la IA depende de las decisiones éticas que tomemos hoy</p>
                </div>
            </div>
        </div>
    </div>

    <div class="navigation">
        <button class="nav-button" id="prevBtn" onclick="changeSlide(-1)">← Anterior</button>
        <button class="nav-button" id="nextBtn" onclick="changeSlide(1)">Siguiente →</button>
    </div>

    <script>
        let currentSlide = 0;
        const slides = document.querySelectorAll('.slide');
        const totalSlides = slides.length;

        document.getElementById('totalSlides').textContent = totalSlides;

        function showSlide(n) {
            slides.forEach(slide => slide.classList.remove('active'));
            
            if (n >= totalSlides) {
                currentSlide = totalSlides - 1;
            } else if (n < 0) {
                currentSlide = 0;
            } else {
                currentSlide = n;
            }
            
            slides[currentSlide].classList.add('active');
            document.getElementById('currentSlide').textContent = currentSlide + 1;
            
            // Update button states
            document.getElementById('prevBtn').disabled = currentSlide === 0;
            document.getElementById('nextBtn').disabled = currentSlide === totalSlides - 1;
        }

        function changeSlide(direction) {
            showSlide(currentSlide + direction);
        }

        // Keyboard navigation
        document.addEventListener('keydown', function(event) {
            if (event.key === 'ArrowLeft') {
                changeSlide(-1);
            } else if (event.key === 'ArrowRight') {
                changeSlide(1);
            }
        });

        // Initialize
        showSlide(0);
    </script>
</body>
</html>
